{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Tweets_Extraction&Cleaning.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CovR4kgnqbiN",
        "outputId": "6a9d4459-999e-4f8c-daae-f64e88009bcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/dist-packages (4.9.0)\n",
            "Requirement already satisfied: requests<3,>=2.27.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (2.27.1)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (3.2.0)\n",
            "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.27.0->tweepy) (2021.10.8)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.27.0->tweepy) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.27.0->tweepy) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.27.0->tweepy) (2.0.12)\n"
          ]
        }
      ],
      "source": [
        "!pip install tweepy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tweepy --upgrade"
      ],
      "metadata": {
        "id": "lq0KOxI5sbuG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 601
        },
        "outputId": "85b95cde-14fe-429d-9a39-a056ea8f413b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.7/dist-packages (3.10.0)\n",
            "Collecting tweepy\n",
            "  Downloading tweepy-4.9.0-py3-none-any.whl (77 kB)\n",
            "\u001b[K     |████████████████████████████████| 77 kB 2.7 MB/s \n",
            "\u001b[?25hCollecting requests<3,>=2.27.0\n",
            "  Downloading requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 929 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (1.3.1)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from tweepy) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.27.0->tweepy) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.27.0->tweepy) (2021.10.8)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.27.0->tweepy) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.27.0->tweepy) (1.24.3)\n",
            "Installing collected packages: requests, tweepy\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: tweepy\n",
            "    Found existing installation: tweepy 3.10.0\n",
            "    Uninstalling tweepy-3.10.0:\n",
            "      Successfully uninstalled tweepy-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.27.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed requests-2.27.1 tweepy-4.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests",
                  "tweepy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install tweet-preprocessor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wdcNDkogS9kL",
        "outputId": "51be7dfc-177d-4da8-979b-0999f9b5b7ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tweet-preprocessor\n",
            "  Downloading tweet_preprocessor-0.6.0-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: tweet-preprocessor\n",
            "Successfully installed tweet-preprocessor-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install spacy-langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "js5qygystvgz",
        "outputId": "0cb0f1eb-a835-48d2-8d0e-20f8dfb994fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacy-langdetect\n",
            "  Downloading spacy_langdetect-0.1.2-py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from spacy-langdetect) (3.6.4)\n",
            "Collecting langdetect==1.0.7\n",
            "  Downloading langdetect-1.0.7.zip (998 kB)\n",
            "\u001b[K     |████████████████████████████████| 998 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from langdetect==1.0.7->spacy-langdetect) (1.15.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->spacy-langdetect) (0.7.1)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->spacy-langdetect) (8.12.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->spacy-langdetect) (1.11.0)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->spacy-langdetect) (1.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->spacy-langdetect) (57.4.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->spacy-langdetect) (21.4.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.7-py3-none-any.whl size=993431 sha256=c2a4cf2a5ce396016d1667a330a97d1d73219af6134fb22173ab9b07d1738a64\n",
            "  Stored in directory: /root/.cache/pip/wheels/89/79/3b/9885ae7f4308f73c514f96d8574d40d7d8173a27731b674013\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect, spacy-langdetect\n",
            "Successfully installed langdetect-1.0.7 spacy-langdetect-0.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tweepy import OAuthHandler\n",
        "\n",
        "import nltk\n",
        "import spacy\n",
        "from spacy_langdetect import LanguageDetector\n",
        "from nltk.corpus import stopwords\n",
        "import preprocessor as p\n",
        "import tweepy \n",
        "import json\n",
        "import pandas as pd\n",
        "import csv\n",
        "import re\n",
        "from textblob import TextBlob\n",
        "import string\n",
        "import regex as re\n",
        "import os\n",
        "import time\n",
        "from datetime import datetime\n",
        "from tweepy import Client\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "5vAkJa51qwHi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tweepy.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K55fbT-dwhHa",
        "outputId": "806be935-4ac2-46c8-9225-f1c478cd7f8e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Twitter credentials\n",
        "# Obtain them from your twitter developer account\n",
        "api_key = 'f480rt4C2qwxWM0sk1FILrRjp'\n",
        "api_secret = 'Hd6aWlaZMV8w0hTHpd3NvIcRlSAUbf4TlfXkRVl7XwUGmlVZTc'\n",
        "access_key = '1524266583686017025-BtwRNUFf8D9cqTwlSgwWHFiboJtov0'\n",
        "access_secret = 'zFqdqTjF6iiDdB3RU0tXJexSZq0QVTlUs8Z2M8QbYRNrk'\n",
        "bearer_token = 'AAAAAAAAAAAAAAAAAAAAANLecQEAAAAAqeNIjyNnoxMUebzlIJfxUF4C8yU%3D2M3QuzL8JWkxTfR0Rzp2TPU8WAyio1vx7cBpfMU3MgkEoNr0GW'\n",
        "client = tweepy.Client(bearer_token)\n"
      ],
      "metadata": {
        "id": "vdcyAUIfrTjM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#response = client.search_recent_tweets(\"elonmusk\")\n",
        "# The method returns a Response object, a named tuple with data, includes,\n",
        "# errors, and meta fields\n",
        "#print(response.meta)\n",
        "\n",
        "# In this case, the data field of the Response returned is a list of Tweet\n",
        "# objects\n",
        "#tweets = response.data\n",
        "\n",
        "# Each Tweet object has default ID and text fields\n",
        "#for tweet in tweets:\n",
        "    #print(tweet.id)\n",
        "    #print(tweet.text)\n",
        "\n",
        "# By default, this endpoint/method returns 10 results\n",
        "# # You can retrieve up to 100 Tweets by specifying max_results\n",
        "# response = client.search_recent_tweets(\"Tweepy\", max_results=100"
      ],
      "metadata": {
        "id": "JgAy33B1dVLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a pandas dataframe to store the date:\n",
        "db_tweets = pd.DataFrame(columns = ['tweetID', 'AuthorID', 'lang','created_at', 'text'])"
      ],
      "metadata": {
        "id": "FLf8a39nF648"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def scraptweets(search_words, db_tweets, no_tweets):\n",
        "    \n",
        "    # Define a for-loop to generate tweets at regular intervals\n",
        "    # We cannot make large API call in one go. Hence, let's try T times\n",
        "                            \n",
        "    start_run = time.time()\n",
        "    \n",
        "    # Collect tweets using the Cursor object\n",
        "    # .Cursor() returns an object that you can iterate or loop over to access the data collected.\n",
        "    # Each item in the iterator has various attributes that you can access to get information about each tweet\n",
        "    tweets = tweepy.Paginator(client.search_recent_tweets, query=search_words, \n",
        "                          tweet_fields=['id', 'created_at', 'author_id'], \n",
        "                          user_fields=['public_metrics', 'location', 'username'],\n",
        "                          max_results=100).flatten(limit=500)\n",
        "    \n",
        "    for tweet in tweets:\n",
        "      # Pull the values\n",
        "      text=tweet.text\n",
        "      author_id = tweet.author_id\n",
        "      tweetID = tweet.id\n",
        "      lang=tweet.lang\n",
        "      created_at=tweet.created_at\n",
        "            \n",
        "      # Add the 11 variables to the empty list - ith_tweet:\n",
        "      ith_tweet = [tweetID, author_id, lang, created_at, text]\n",
        "      # Append to dataframe - db_tweets\n",
        "      try:\n",
        "        db_tweets.loc[len(db_tweets)] = ith_tweet\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "      # increase counter - noTweets  \n",
        "      no_tweets += 1\n",
        "    \n",
        "    # Run ended:\n",
        "    end_run = time.time()\n",
        "    duration_run = round((end_run-start_run)/60, 2)\n",
        "    \n",
        "    print('no. of tweets scraped for run 1 is {}'.format(no_tweets))\n",
        "    print('time take for 1 run to complete is {} mins'.format(duration_run))\n",
        "    \n",
        "    return no_tweets\n",
        "    "
      ],
      "metadata": {
        "id": "pdOwTWv3s5_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_runs=981\n",
        "tweets=0\n",
        "for i in range(num_runs):\n",
        "  search_words = '#Hospitalstay OR #hospitalvisit OR #emergencyroomvisit OR #ERvisit OR #Hospitalexperience OR #patientexperience OR #Health OR #patient OR #trauma OR #surgery OR #critical OR #procedure OR #symptoms OR #pain OR #medicine'\n",
        "  # Call the function scraptweets\n",
        "  tweets=scraptweets(search_words, db_tweets, tweets)\n",
        "\n",
        "  #new search word string\n",
        "  search_words = 'Hospital stay OR hospital visit OR emergencyroom visit OR ER visit OR Hospital experience OR patient,  experience OR Health OR patient OR trauma OR surgery OR critical OR procedure OR symptoms OR pain OR medicine'\n",
        "  # Call the function scraptweets\n",
        "  tweets=scraptweets(search_words, db_tweets, tweets)\n",
        "\n",
        "  #new search word string\n",
        "  search_words = 'Hospital OR clinic OR urgent care OR emergency room OR ED OR Nurse OR doctor OR medical professional OR registered nurse OR dr OR patient rep OR patinet engagement OR Treatment OR treat OR assist OR care OR Surgery OR IV OR blood OR ICU OR NICU OR urgent care OR emergency room OR triage OR ED OR bill OR doctor OR bill OR health insurance OR Monitor OR heal OR recover OR care OR cure OR dying OR dead OR sicker OR sick OR ill OR illness OR condition '\n",
        "  # Call the function scraptweets\n",
        "  tweets=scraptweets(search_words, db_tweets, tweets)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KbcktdmzTDtu",
        "outputId": "37fd1155-069c-4123-affd-4047626ef07a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no. of tweets scraped for run 1 is 500\n",
            "time take for 1 run to complete is 0.07 mins\n",
            "no. of tweets scraped for run 1 is 1000\n",
            "time take for 1 run to complete is 0.07 mins\n",
            "no. of tweets scraped for run 1 is 1500\n",
            "time take for 1 run to complete is 0.09 mins\n",
            "no. of tweets scraped for run 1 is 2000\n",
            "time take for 1 run to complete is 0.09 mins\n",
            "no. of tweets scraped for run 1 is 2500\n",
            "time take for 1 run to complete is 0.09 mins\n",
            "no. of tweets scraped for run 1 is 3000\n",
            "time take for 1 run to complete is 0.21 mins\n",
            "no. of tweets scraped for run 1 is 3500\n",
            "time take for 1 run to complete is 0.2 mins\n",
            "no. of tweets scraped for run 1 is 4000\n",
            "time take for 1 run to complete is 0.17 mins\n",
            "no. of tweets scraped for run 1 is 4500\n",
            "time take for 1 run to complete is 0.12 mins\n",
            "no. of tweets scraped for run 1 is 5000\n",
            "time take for 1 run to complete is 0.12 mins\n",
            "no. of tweets scraped for run 1 is 5500\n",
            "time take for 1 run to complete is 0.13 mins\n",
            "no. of tweets scraped for run 1 is 6000\n",
            "time take for 1 run to complete is 0.14 mins\n",
            "no. of tweets scraped for run 1 is 6500\n",
            "time take for 1 run to complete is 0.14 mins\n",
            "no. of tweets scraped for run 1 is 7000\n",
            "time take for 1 run to complete is 0.15 mins\n",
            "no. of tweets scraped for run 1 is 7500\n",
            "time take for 1 run to complete is 0.15 mins\n",
            "no. of tweets scraped for run 1 is 8000\n",
            "time take for 1 run to complete is 0.16 mins\n",
            "no. of tweets scraped for run 1 is 8500\n",
            "time take for 1 run to complete is 0.17 mins\n",
            "no. of tweets scraped for run 1 is 9000\n",
            "time take for 1 run to complete is 0.18 mins\n",
            "no. of tweets scraped for run 1 is 9500\n",
            "time take for 1 run to complete is 0.18 mins\n",
            "no. of tweets scraped for run 1 is 10000\n",
            "time take for 1 run to complete is 0.18 mins\n",
            "no. of tweets scraped for run 1 is 10500\n",
            "time take for 1 run to complete is 0.19 mins\n",
            "no. of tweets scraped for run 1 is 11000\n",
            "time take for 1 run to complete is 0.19 mins\n",
            "no. of tweets scraped for run 1 is 11500\n",
            "time take for 1 run to complete is 0.2 mins\n",
            "no. of tweets scraped for run 1 is 12000\n",
            "time take for 1 run to complete is 0.21 mins\n",
            "no. of tweets scraped for run 1 is 12500\n",
            "time take for 1 run to complete is 0.21 mins\n",
            "no. of tweets scraped for run 1 is 13000\n",
            "time take for 1 run to complete is 0.22 mins\n",
            "no. of tweets scraped for run 1 is 13500\n",
            "time take for 1 run to complete is 0.22 mins\n",
            "no. of tweets scraped for run 1 is 14000\n",
            "time take for 1 run to complete is 0.23 mins\n",
            "no. of tweets scraped for run 1 is 14500\n",
            "time take for 1 run to complete is 0.24 mins\n",
            "no. of tweets scraped for run 1 is 15000\n",
            "time take for 1 run to complete is 0.39 mins\n",
            "no. of tweets scraped for run 1 is 15500\n",
            "time take for 1 run to complete is 0.35 mins\n",
            "no. of tweets scraped for run 1 is 16000\n",
            "time take for 1 run to complete is 0.25 mins\n",
            "no. of tweets scraped for run 1 is 16500\n",
            "time take for 1 run to complete is 0.27 mins\n",
            "no. of tweets scraped for run 1 is 17000\n",
            "time take for 1 run to complete is 0.27 mins\n",
            "no. of tweets scraped for run 1 is 17500\n",
            "time take for 1 run to complete is 0.27 mins\n",
            "no. of tweets scraped for run 1 is 18000\n",
            "time take for 1 run to complete is 0.28 mins\n",
            "no. of tweets scraped for run 1 is 18500\n",
            "time take for 1 run to complete is 0.29 mins\n",
            "no. of tweets scraped for run 1 is 19000\n",
            "time take for 1 run to complete is 0.29 mins\n",
            "no. of tweets scraped for run 1 is 19500\n",
            "time take for 1 run to complete is 0.3 mins\n",
            "no. of tweets scraped for run 1 is 20000\n",
            "time take for 1 run to complete is 0.3 mins\n",
            "no. of tweets scraped for run 1 is 20500\n",
            "time take for 1 run to complete is 0.32 mins\n",
            "no. of tweets scraped for run 1 is 21000\n",
            "time take for 1 run to complete is 0.31 mins\n",
            "no. of tweets scraped for run 1 is 21500\n",
            "time take for 1 run to complete is 0.32 mins\n",
            "no. of tweets scraped for run 1 is 22000\n",
            "time take for 1 run to complete is 0.33 mins\n",
            "no. of tweets scraped for run 1 is 22500\n",
            "time take for 1 run to complete is 0.33 mins\n",
            "no. of tweets scraped for run 1 is 23000\n",
            "time take for 1 run to complete is 0.34 mins\n",
            "no. of tweets scraped for run 1 is 23500\n",
            "time take for 1 run to complete is 0.35 mins\n",
            "no. of tweets scraped for run 1 is 24000\n",
            "time take for 1 run to complete is 0.36 mins\n",
            "no. of tweets scraped for run 1 is 24500\n",
            "time take for 1 run to complete is 0.36 mins\n",
            "no. of tweets scraped for run 1 is 25000\n",
            "time take for 1 run to complete is 0.36 mins\n",
            "no. of tweets scraped for run 1 is 25500\n",
            "time take for 1 run to complete is 0.37 mins\n",
            "no. of tweets scraped for run 1 is 26000\n",
            "time take for 1 run to complete is 0.37 mins\n",
            "no. of tweets scraped for run 1 is 26500\n",
            "time take for 1 run to complete is 0.38 mins\n",
            "no. of tweets scraped for run 1 is 27000\n",
            "time take for 1 run to complete is 0.39 mins\n",
            "no. of tweets scraped for run 1 is 27500\n",
            "time take for 1 run to complete is 0.41 mins\n",
            "no. of tweets scraped for run 1 is 28000\n",
            "time take for 1 run to complete is 0.41 mins\n",
            "no. of tweets scraped for run 1 is 28500\n",
            "time take for 1 run to complete is 0.41 mins\n",
            "no. of tweets scraped for run 1 is 29000\n",
            "time take for 1 run to complete is 0.41 mins\n",
            "no. of tweets scraped for run 1 is 29500\n",
            "time take for 1 run to complete is 0.42 mins\n",
            "no. of tweets scraped for run 1 is 30000\n",
            "time take for 1 run to complete is 0.43 mins\n",
            "no. of tweets scraped for run 1 is 30500\n",
            "time take for 1 run to complete is 0.45 mins\n",
            "no. of tweets scraped for run 1 is 31000\n",
            "time take for 1 run to complete is 0.44 mins\n",
            "no. of tweets scraped for run 1 is 31500\n",
            "time take for 1 run to complete is 0.44 mins\n",
            "no. of tweets scraped for run 1 is 32000\n",
            "time take for 1 run to complete is 0.45 mins\n",
            "no. of tweets scraped for run 1 is 32500\n",
            "time take for 1 run to complete is 0.46 mins\n",
            "no. of tweets scraped for run 1 is 33000\n",
            "time take for 1 run to complete is 0.46 mins\n",
            "no. of tweets scraped for run 1 is 33500\n",
            "time take for 1 run to complete is 0.48 mins\n",
            "no. of tweets scraped for run 1 is 34000\n",
            "time take for 1 run to complete is 0.48 mins\n",
            "no. of tweets scraped for run 1 is 34500\n",
            "time take for 1 run to complete is 0.49 mins\n",
            "no. of tweets scraped for run 1 is 35000\n",
            "time take for 1 run to complete is 0.52 mins\n",
            "no. of tweets scraped for run 1 is 35500\n",
            "time take for 1 run to complete is 0.52 mins\n",
            "no. of tweets scraped for run 1 is 36000\n",
            "time take for 1 run to complete is 0.52 mins\n",
            "no. of tweets scraped for run 1 is 36500\n",
            "time take for 1 run to complete is 0.51 mins\n",
            "no. of tweets scraped for run 1 is 37000\n",
            "time take for 1 run to complete is 0.55 mins\n",
            "no. of tweets scraped for run 1 is 37500\n",
            "time take for 1 run to complete is 0.58 mins\n",
            "no. of tweets scraped for run 1 is 38000\n",
            "time take for 1 run to complete is 0.53 mins\n",
            "no. of tweets scraped for run 1 is 38500\n",
            "time take for 1 run to complete is 0.53 mins\n",
            "no. of tweets scraped for run 1 is 39000\n",
            "time take for 1 run to complete is 0.55 mins\n",
            "no. of tweets scraped for run 1 is 39500\n",
            "time take for 1 run to complete is 0.56 mins\n",
            "no. of tweets scraped for run 1 is 40000\n",
            "time take for 1 run to complete is 0.57 mins\n",
            "no. of tweets scraped for run 1 is 40500\n",
            "time take for 1 run to complete is 0.55 mins\n",
            "no. of tweets scraped for run 1 is 41000\n",
            "time take for 1 run to complete is 0.57 mins\n",
            "no. of tweets scraped for run 1 is 41500\n",
            "time take for 1 run to complete is 0.57 mins\n",
            "no. of tweets scraped for run 1 is 42000\n",
            "time take for 1 run to complete is 0.57 mins\n",
            "no. of tweets scraped for run 1 is 42500\n",
            "time take for 1 run to complete is 0.58 mins\n",
            "no. of tweets scraped for run 1 is 43000\n",
            "time take for 1 run to complete is 0.6 mins\n",
            "no. of tweets scraped for run 1 is 43500\n",
            "time take for 1 run to complete is 0.6 mins\n",
            "no. of tweets scraped for run 1 is 44000\n",
            "time take for 1 run to complete is 0.59 mins\n",
            "no. of tweets scraped for run 1 is 44500\n",
            "time take for 1 run to complete is 0.6 mins\n",
            "no. of tweets scraped for run 1 is 45000\n",
            "time take for 1 run to complete is 0.61 mins\n",
            "no. of tweets scraped for run 1 is 45500\n",
            "time take for 1 run to complete is 0.61 mins\n",
            "no. of tweets scraped for run 1 is 46000\n",
            "time take for 1 run to complete is 0.62 mins\n",
            "no. of tweets scraped for run 1 is 46500\n",
            "time take for 1 run to complete is 0.62 mins\n",
            "no. of tweets scraped for run 1 is 47000\n",
            "time take for 1 run to complete is 0.63 mins\n",
            "no. of tweets scraped for run 1 is 47500\n",
            "time take for 1 run to complete is 0.63 mins\n",
            "no. of tweets scraped for run 1 is 48000\n",
            "time take for 1 run to complete is 0.63 mins\n",
            "no. of tweets scraped for run 1 is 48500\n",
            "time take for 1 run to complete is 0.64 mins\n",
            "no. of tweets scraped for run 1 is 49000\n",
            "time take for 1 run to complete is 0.65 mins\n",
            "no. of tweets scraped for run 1 is 49500\n",
            "time take for 1 run to complete is 0.65 mins\n",
            "no. of tweets scraped for run 1 is 50000\n",
            "time take for 1 run to complete is 0.73 mins\n",
            "no. of tweets scraped for run 1 is 50500\n",
            "time take for 1 run to complete is 0.67 mins\n",
            "no. of tweets scraped for run 1 is 51000\n",
            "time take for 1 run to complete is 0.68 mins\n",
            "no. of tweets scraped for run 1 is 51500\n",
            "time take for 1 run to complete is 0.68 mins\n",
            "no. of tweets scraped for run 1 is 52000\n",
            "time take for 1 run to complete is 0.68 mins\n",
            "no. of tweets scraped for run 1 is 52500\n",
            "time take for 1 run to complete is 0.69 mins\n",
            "no. of tweets scraped for run 1 is 53000\n",
            "time take for 1 run to complete is 0.69 mins\n",
            "no. of tweets scraped for run 1 is 53500\n",
            "time take for 1 run to complete is 0.71 mins\n",
            "no. of tweets scraped for run 1 is 54000\n",
            "time take for 1 run to complete is 0.71 mins\n",
            "no. of tweets scraped for run 1 is 54500\n",
            "time take for 1 run to complete is 0.73 mins\n",
            "no. of tweets scraped for run 1 is 55000\n",
            "time take for 1 run to complete is 0.72 mins\n",
            "no. of tweets scraped for run 1 is 55500\n",
            "time take for 1 run to complete is 0.73 mins\n",
            "no. of tweets scraped for run 1 is 56000\n",
            "time take for 1 run to complete is 0.75 mins\n",
            "no. of tweets scraped for run 1 is 56500\n",
            "time take for 1 run to complete is 0.75 mins\n",
            "no. of tweets scraped for run 1 is 57000\n",
            "time take for 1 run to complete is 0.76 mins\n",
            "no. of tweets scraped for run 1 is 57500\n",
            "time take for 1 run to complete is 0.76 mins\n",
            "no. of tweets scraped for run 1 is 58000\n",
            "time take for 1 run to complete is 0.76 mins\n",
            "no. of tweets scraped for run 1 is 58500\n",
            "time take for 1 run to complete is 0.78 mins\n",
            "no. of tweets scraped for run 1 is 59000\n",
            "time take for 1 run to complete is 0.81 mins\n",
            "no. of tweets scraped for run 1 is 59500\n",
            "time take for 1 run to complete is 0.8 mins\n",
            "no. of tweets scraped for run 1 is 60000\n",
            "time take for 1 run to complete is 0.78 mins\n",
            "no. of tweets scraped for run 1 is 60500\n",
            "time take for 1 run to complete is 0.79 mins\n",
            "no. of tweets scraped for run 1 is 61000\n",
            "time take for 1 run to complete is 0.8 mins\n",
            "no. of tweets scraped for run 1 is 61500\n",
            "time take for 1 run to complete is 0.81 mins\n",
            "no. of tweets scraped for run 1 is 62000\n",
            "time take for 1 run to complete is 0.81 mins\n",
            "no. of tweets scraped for run 1 is 62500\n",
            "time take for 1 run to complete is 0.81 mins\n",
            "no. of tweets scraped for run 1 is 63000\n",
            "time take for 1 run to complete is 0.81 mins\n",
            "no. of tweets scraped for run 1 is 63500\n",
            "time take for 1 run to complete is 0.82 mins\n",
            "no. of tweets scraped for run 1 is 64000\n",
            "time take for 1 run to complete is 0.83 mins\n",
            "no. of tweets scraped for run 1 is 64500\n",
            "time take for 1 run to complete is 0.84 mins\n",
            "no. of tweets scraped for run 1 is 65000\n",
            "time take for 1 run to complete is 0.85 mins\n",
            "no. of tweets scraped for run 1 is 65500\n",
            "time take for 1 run to complete is 0.86 mins\n",
            "no. of tweets scraped for run 1 is 66000\n",
            "time take for 1 run to complete is 0.86 mins\n",
            "no. of tweets scraped for run 1 is 66500\n",
            "time take for 1 run to complete is 0.87 mins\n",
            "no. of tweets scraped for run 1 is 67000\n",
            "time take for 1 run to complete is 0.86 mins\n",
            "no. of tweets scraped for run 1 is 67500\n",
            "time take for 1 run to complete is 0.87 mins\n",
            "no. of tweets scraped for run 1 is 68000\n",
            "time take for 1 run to complete is 0.88 mins\n",
            "no. of tweets scraped for run 1 is 68500\n",
            "time take for 1 run to complete is 0.89 mins\n",
            "no. of tweets scraped for run 1 is 69000\n",
            "time take for 1 run to complete is 0.89 mins\n",
            "no. of tweets scraped for run 1 is 69500\n",
            "time take for 1 run to complete is 0.89 mins\n",
            "no. of tweets scraped for run 1 is 70000\n",
            "time take for 1 run to complete is 0.91 mins\n",
            "no. of tweets scraped for run 1 is 70500\n",
            "time take for 1 run to complete is 0.91 mins\n",
            "no. of tweets scraped for run 1 is 71000\n",
            "time take for 1 run to complete is 0.91 mins\n",
            "no. of tweets scraped for run 1 is 71500\n",
            "time take for 1 run to complete is 0.92 mins\n",
            "no. of tweets scraped for run 1 is 72000\n",
            "time take for 1 run to complete is 0.92 mins\n",
            "no. of tweets scraped for run 1 is 72500\n",
            "time take for 1 run to complete is 0.93 mins\n",
            "no. of tweets scraped for run 1 is 73000\n",
            "time take for 1 run to complete is 0.94 mins\n",
            "no. of tweets scraped for run 1 is 73500\n",
            "time take for 1 run to complete is 0.94 mins\n",
            "no. of tweets scraped for run 1 is 74000\n",
            "time take for 1 run to complete is 0.95 mins\n",
            "no. of tweets scraped for run 1 is 74500\n",
            "time take for 1 run to complete is 0.96 mins\n",
            "no. of tweets scraped for run 1 is 75000\n",
            "time take for 1 run to complete is 0.98 mins\n",
            "no. of tweets scraped for run 1 is 75500\n",
            "time take for 1 run to complete is 0.99 mins\n",
            "no. of tweets scraped for run 1 is 76000\n",
            "time take for 1 run to complete is 0.97 mins\n",
            "no. of tweets scraped for run 1 is 76500\n",
            "time take for 1 run to complete is 0.97 mins\n",
            "no. of tweets scraped for run 1 is 77000\n",
            "time take for 1 run to complete is 1.01 mins\n",
            "no. of tweets scraped for run 1 is 77500\n",
            "time take for 1 run to complete is 1.07 mins\n",
            "no. of tweets scraped for run 1 is 78000\n",
            "time take for 1 run to complete is 1.0 mins\n",
            "no. of tweets scraped for run 1 is 78500\n",
            "time take for 1 run to complete is 1.01 mins\n",
            "no. of tweets scraped for run 1 is 79000\n",
            "time take for 1 run to complete is 1.01 mins\n",
            "no. of tweets scraped for run 1 is 79500\n",
            "time take for 1 run to complete is 1.06 mins\n",
            "no. of tweets scraped for run 1 is 80000\n",
            "time take for 1 run to complete is 1.03 mins\n",
            "no. of tweets scraped for run 1 is 80500\n",
            "time take for 1 run to complete is 1.03 mins\n",
            "no. of tweets scraped for run 1 is 81000\n",
            "time take for 1 run to complete is 1.06 mins\n",
            "no. of tweets scraped for run 1 is 81500\n",
            "time take for 1 run to complete is 1.07 mins\n",
            "no. of tweets scraped for run 1 is 82000\n",
            "time take for 1 run to complete is 1.06 mins\n",
            "no. of tweets scraped for run 1 is 82500\n",
            "time take for 1 run to complete is 1.08 mins\n",
            "no. of tweets scraped for run 1 is 83000\n",
            "time take for 1 run to complete is 1.06 mins\n",
            "no. of tweets scraped for run 1 is 83500\n",
            "time take for 1 run to complete is 1.06 mins\n",
            "no. of tweets scraped for run 1 is 84000\n",
            "time take for 1 run to complete is 1.06 mins\n",
            "no. of tweets scraped for run 1 is 84500\n",
            "time take for 1 run to complete is 1.08 mins\n",
            "no. of tweets scraped for run 1 is 85000\n",
            "time take for 1 run to complete is 1.09 mins\n",
            "no. of tweets scraped for run 1 is 85500\n",
            "time take for 1 run to complete is 1.09 mins\n",
            "no. of tweets scraped for run 1 is 86000\n",
            "time take for 1 run to complete is 1.11 mins\n",
            "no. of tweets scraped for run 1 is 86500\n",
            "time take for 1 run to complete is 1.09 mins\n",
            "no. of tweets scraped for run 1 is 87000\n",
            "time take for 1 run to complete is 1.11 mins\n",
            "no. of tweets scraped for run 1 is 87500\n",
            "time take for 1 run to complete is 1.11 mins\n",
            "no. of tweets scraped for run 1 is 88000\n",
            "time take for 1 run to complete is 1.18 mins\n",
            "no. of tweets scraped for run 1 is 88500\n",
            "time take for 1 run to complete is 1.2 mins\n",
            "no. of tweets scraped for run 1 is 89000\n",
            "time take for 1 run to complete is 1.21 mins\n",
            "no. of tweets scraped for run 1 is 89500\n",
            "time take for 1 run to complete is 1.22 mins\n",
            "no. of tweets scraped for run 1 is 90000\n",
            "time take for 1 run to complete is 1.21 mins\n",
            "no. of tweets scraped for run 1 is 90500\n",
            "time take for 1 run to complete is 1.21 mins\n",
            "no. of tweets scraped for run 1 is 91000\n",
            "time take for 1 run to complete is 1.21 mins\n",
            "no. of tweets scraped for run 1 is 91500\n",
            "time take for 1 run to complete is 1.22 mins\n",
            "no. of tweets scraped for run 1 is 92000\n",
            "time take for 1 run to complete is 1.22 mins\n",
            "no. of tweets scraped for run 1 is 92500\n",
            "time take for 1 run to complete is 1.24 mins\n",
            "no. of tweets scraped for run 1 is 93000\n",
            "time take for 1 run to complete is 1.26 mins\n",
            "no. of tweets scraped for run 1 is 93500\n",
            "time take for 1 run to complete is 1.27 mins\n",
            "no. of tweets scraped for run 1 is 94000\n",
            "time take for 1 run to complete is 1.25 mins\n",
            "no. of tweets scraped for run 1 is 94500\n",
            "time take for 1 run to complete is 1.25 mins\n",
            "no. of tweets scraped for run 1 is 95000\n",
            "time take for 1 run to complete is 1.27 mins\n",
            "no. of tweets scraped for run 1 is 95500\n",
            "time take for 1 run to complete is 1.29 mins\n",
            "no. of tweets scraped for run 1 is 96000\n",
            "time take for 1 run to complete is 1.3 mins\n",
            "no. of tweets scraped for run 1 is 96500\n",
            "time take for 1 run to complete is 1.29 mins\n",
            "no. of tweets scraped for run 1 is 97000\n",
            "time take for 1 run to complete is 1.29 mins\n",
            "no. of tweets scraped for run 1 is 97500\n",
            "time take for 1 run to complete is 1.3 mins\n",
            "no. of tweets scraped for run 1 is 98000\n",
            "time take for 1 run to complete is 1.32 mins\n",
            "no. of tweets scraped for run 1 is 98500\n",
            "time take for 1 run to complete is 1.32 mins\n",
            "no. of tweets scraped for run 1 is 99000\n",
            "time take for 1 run to complete is 1.31 mins\n",
            "no. of tweets scraped for run 1 is 99500\n",
            "time take for 1 run to complete is 1.34 mins\n",
            "no. of tweets scraped for run 1 is 100000\n",
            "time take for 1 run to complete is 1.33 mins\n",
            "no. of tweets scraped for run 1 is 100500\n",
            "time take for 1 run to complete is 1.32 mins\n",
            "no. of tweets scraped for run 1 is 101000\n",
            "time take for 1 run to complete is 1.34 mins\n",
            "no. of tweets scraped for run 1 is 101500\n",
            "time take for 1 run to complete is 1.35 mins\n",
            "no. of tweets scraped for run 1 is 102000\n",
            "time take for 1 run to complete is 1.36 mins\n",
            "no. of tweets scraped for run 1 is 102500\n",
            "time take for 1 run to complete is 1.36 mins\n",
            "no. of tweets scraped for run 1 is 103000\n",
            "time take for 1 run to complete is 1.37 mins\n",
            "no. of tweets scraped for run 1 is 103500\n",
            "time take for 1 run to complete is 1.39 mins\n",
            "no. of tweets scraped for run 1 is 104000\n",
            "time take for 1 run to complete is 1.39 mins\n",
            "no. of tweets scraped for run 1 is 104500\n",
            "time take for 1 run to complete is 1.39 mins\n",
            "no. of tweets scraped for run 1 is 105000\n",
            "time take for 1 run to complete is 1.39 mins\n",
            "no. of tweets scraped for run 1 is 105500\n",
            "time take for 1 run to complete is 1.4 mins\n",
            "no. of tweets scraped for run 1 is 106000\n",
            "time take for 1 run to complete is 1.41 mins\n",
            "no. of tweets scraped for run 1 is 106500\n",
            "time take for 1 run to complete is 1.42 mins\n",
            "no. of tweets scraped for run 1 is 107000\n",
            "time take for 1 run to complete is 1.42 mins\n",
            "no. of tweets scraped for run 1 is 107500\n",
            "time take for 1 run to complete is 1.45 mins\n",
            "no. of tweets scraped for run 1 is 108000\n",
            "time take for 1 run to complete is 1.44 mins\n",
            "no. of tweets scraped for run 1 is 108500\n",
            "time take for 1 run to complete is 1.44 mins\n",
            "no. of tweets scraped for run 1 is 109000\n",
            "time take for 1 run to complete is 1.46 mins\n",
            "no. of tweets scraped for run 1 is 109500\n",
            "time take for 1 run to complete is 1.45 mins\n",
            "no. of tweets scraped for run 1 is 110000\n",
            "time take for 1 run to complete is 1.46 mins\n",
            "no. of tweets scraped for run 1 is 110500\n",
            "time take for 1 run to complete is 1.46 mins\n",
            "no. of tweets scraped for run 1 is 111000\n",
            "time take for 1 run to complete is 1.46 mins\n",
            "no. of tweets scraped for run 1 is 111500\n",
            "time take for 1 run to complete is 1.48 mins\n",
            "no. of tweets scraped for run 1 is 112000\n",
            "time take for 1 run to complete is 1.52 mins\n",
            "no. of tweets scraped for run 1 is 112500\n",
            "time take for 1 run to complete is 1.51 mins\n",
            "no. of tweets scraped for run 1 is 113000\n",
            "time take for 1 run to complete is 1.5 mins\n",
            "no. of tweets scraped for run 1 is 113500\n",
            "time take for 1 run to complete is 1.52 mins\n",
            "no. of tweets scraped for run 1 is 114000\n",
            "time take for 1 run to complete is 1.52 mins\n",
            "no. of tweets scraped for run 1 is 114500\n",
            "time take for 1 run to complete is 1.54 mins\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-94ca9c5af6e0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0msearch_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Hospital stay OR hospital visit OR emergencyroom visit OR ER visit OR Hospital experience OR patient,  experience OR Health OR patient OR trauma OR surgery OR critical OR procedure OR symptoms OR pain OR medicine'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m   \u001b[0;31m# Call the function scraptweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mtweets\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscraptweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdb_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m#new search word string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-61-7fd78ca65b34>\u001b[0m in \u001b[0;36mscraptweets\u001b[0;34m(search_words, db_tweets, no_tweets)\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0;31m# Append to dataframe - db_tweets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mdb_tweets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdb_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mith_tweet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    722\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 723\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    724\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1723\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1724\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1725\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1726\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_missing\u001b[0;34m(self, indexer, value)\u001b[0m\n\u001b[1;32m   2029\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2030\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2031\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2032\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclear\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ignore_index, verify_integrity, sort)\u001b[0m\n\u001b[1;32m   8967\u001b[0m                 \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8968\u001b[0m                 \u001b[0mverify_integrity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverify_integrity\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8969\u001b[0;31m                 \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8970\u001b[0m             )\n\u001b[1;32m   8971\u001b[0m         ).__finalize__(self, method=\"append\")\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    305\u001b[0m     )\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/reshape/concat.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    531\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             new_data = concatenate_managers(\n\u001b[0;32m--> 533\u001b[0;31m                 \u001b[0mmgrs_indexers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_axes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbm_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    534\u001b[0m             )\n\u001b[1;32m    535\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0mfastpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_join_units\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin_units\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconcat_axis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m             \u001b[0mfastpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36m_concatenate_join_units\u001b[0;34m(join_units, concat_axis, copy)\u001b[0m\n\u001b[1;32m    490\u001b[0m     to_concat = [\n\u001b[1;32m    491\u001b[0m         \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reindexed_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcasted_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m     ]\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    490\u001b[0m     to_concat = [\n\u001b[1;32m    491\u001b[0m         \u001b[0mju\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_reindexed_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupcasted_na\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 492\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mju\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjoin_units\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    493\u001b[0m     ]\n\u001b[1;32m    494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mget_reindexed_values\u001b[0;34m(self, empty_dtype, upcasted_na)\u001b[0m\n\u001b[1;32m    409\u001b[0m             \u001b[0mfill_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupcasted_na\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 411\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_valid_na_for\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mempty_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    412\u001b[0m                 \u001b[0mblk_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"dtype\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36mis_valid_na_for\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_valid_na_for_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"K\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         if self.dtype.kind == dtype.kind == \"M\" and not is_dtype_equal(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/internals/concat.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_valid_na_for_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"K\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         if self.dtype.kind == dtype.kind == \"M\" and not is_dtype_equal(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/dtypes/missing.py\u001b[0m in \u001b[0;36mis_valid_na_for_dtype\u001b[0;34m(obj, dtype)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNaT\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;31m# This is needed for Categorical, but is kind of weird\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db_tweets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 661
        },
        "id": "-fgqQwLuGG5L",
        "outputId": "b7137d7a-ed74-440c-8a4e-29358ed191b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    tweetID             AuthorID  lang  \\\n",
              "0       1525086668348346368  1524037408047644672  None   \n",
              "1       1525086665236434945   709580995155136513  None   \n",
              "2       1525086655438327809  1151202637582348294  None   \n",
              "3       1525086632847757314  1524037408047644672  None   \n",
              "4       1525086553978060810            701079038  None   \n",
              "...                     ...                  ...   ...   \n",
              "114952  1525131356480581632  1320615780552044544  None   \n",
              "114953  1525131355138494466             20157199  None   \n",
              "114954  1525131354853154816  1468522753909489664  None   \n",
              "114955  1525131354815479808  1001715489951842304  None   \n",
              "114956  1525131354664488962            597674628  None   \n",
              "\n",
              "                      created_at  \\\n",
              "0      2022-05-13 12:12:51+00:00   \n",
              "1      2022-05-13 12:12:50+00:00   \n",
              "2      2022-05-13 12:12:48+00:00   \n",
              "3      2022-05-13 12:12:42+00:00   \n",
              "4      2022-05-13 12:12:23+00:00   \n",
              "...                          ...   \n",
              "114952 2022-05-13 15:10:25+00:00   \n",
              "114953 2022-05-13 15:10:25+00:00   \n",
              "114954 2022-05-13 15:10:25+00:00   \n",
              "114955 2022-05-13 15:10:25+00:00   \n",
              "114956 2022-05-13 15:10:25+00:00   \n",
              "\n",
              "                                                     text  \n",
              "0       RT @model_svirid: #Billionaires!#Millionaires!...  \n",
              "1       RT @harrypetsanis: There is no such thing as '...  \n",
              "2       RT @model_svirid: #Billionaires!#Millionaires!...  \n",
              "3       #Billionaires!#Millionaires!#Sponsors!#Philant...  \n",
              "4       RT @ANMF_MeunerieFr: 🌾Décryptage #meunerie🥖Sur...  \n",
              "...                                                   ...  \n",
              "114952  RT @redjaspershopp: Just ONE day away! \\nStop ...  \n",
              "114953  RT @GordonBrown: Tragically, we are sleepwalki...  \n",
              "114954  RT @ujjainumc: @ujjainumc jas made Green Net c...  \n",
              "114955  @RockstarGames @GTASeries @_HEALTH_ so you ack...  \n",
              "114956  RT @erdocAA: Nothing I ever learned in medical...  \n",
              "\n",
              "[114957 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a059cd8-0b89-427b-8f32-ac2555685d3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweetID</th>\n",
              "      <th>AuthorID</th>\n",
              "      <th>lang</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1525086668348346368</td>\n",
              "      <td>1524037408047644672</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 12:12:51+00:00</td>\n",
              "      <td>RT @model_svirid: #Billionaires!#Millionaires!...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1525086665236434945</td>\n",
              "      <td>709580995155136513</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 12:12:50+00:00</td>\n",
              "      <td>RT @harrypetsanis: There is no such thing as '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1525086655438327809</td>\n",
              "      <td>1151202637582348294</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 12:12:48+00:00</td>\n",
              "      <td>RT @model_svirid: #Billionaires!#Millionaires!...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1525086632847757314</td>\n",
              "      <td>1524037408047644672</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 12:12:42+00:00</td>\n",
              "      <td>#Billionaires!#Millionaires!#Sponsors!#Philant...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1525086553978060810</td>\n",
              "      <td>701079038</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 12:12:23+00:00</td>\n",
              "      <td>RT @ANMF_MeunerieFr: 🌾Décryptage #meunerie🥖Sur...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114952</th>\n",
              "      <td>1525131356480581632</td>\n",
              "      <td>1320615780552044544</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 15:10:25+00:00</td>\n",
              "      <td>RT @redjaspershopp: Just ONE day away! \\nStop ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114953</th>\n",
              "      <td>1525131355138494466</td>\n",
              "      <td>20157199</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 15:10:25+00:00</td>\n",
              "      <td>RT @GordonBrown: Tragically, we are sleepwalki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114954</th>\n",
              "      <td>1525131354853154816</td>\n",
              "      <td>1468522753909489664</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 15:10:25+00:00</td>\n",
              "      <td>RT @ujjainumc: @ujjainumc jas made Green Net c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114955</th>\n",
              "      <td>1525131354815479808</td>\n",
              "      <td>1001715489951842304</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 15:10:25+00:00</td>\n",
              "      <td>@RockstarGames @GTASeries @_HEALTH_ so you ack...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114956</th>\n",
              "      <td>1525131354664488962</td>\n",
              "      <td>597674628</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 15:10:25+00:00</td>\n",
              "      <td>RT @erdocAA: Nothing I ever learned in medical...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114957 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a059cd8-0b89-427b-8f32-ac2555685d3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a059cd8-0b89-427b-8f32-ac2555685d3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a059cd8-0b89-427b-8f32-ac2555685d3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unique1= db_tweets['tweetID'].unique()\n",
        "unique2=db_tweets['text'].unique()"
      ],
      "metadata": {
        "id": "D7jL5FvsHBJy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(unique1), ' ',  len(unique2))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URIibp_fR-3K",
        "outputId": "7bf4d2a6-32fc-4e1d-8a71-cd9ae86bb1b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78232   47992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "db_tweets.drop_duplicates(subset =\"tweetID\",\n",
        "                     keep = False, inplace = True)"
      ],
      "metadata": {
        "id": "KlGEgXzOPMTG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_tweets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 641
        },
        "id": "s9MzVBw3-x47",
        "outputId": "56552255-a702-4407-e502-8b591de60600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                    tweetID             AuthorID  lang  \\\n",
              "497     1525079862410625024  1299576198591385600  None   \n",
              "498     1525079857201352704           1334017178  None   \n",
              "499     1525079805674274816  1189832851371347969  None   \n",
              "808     1525086602439057408  1518709954215124993  None   \n",
              "809     1525086602195787776            355844222  None   \n",
              "...                     ...                  ...   ...   \n",
              "114952  1525131356480581632  1320615780552044544  None   \n",
              "114953  1525131355138494466             20157199  None   \n",
              "114954  1525131354853154816  1468522753909489664  None   \n",
              "114955  1525131354815479808  1001715489951842304  None   \n",
              "114956  1525131354664488962            597674628  None   \n",
              "\n",
              "                      created_at  \\\n",
              "497    2022-05-13 11:45:48+00:00   \n",
              "498    2022-05-13 11:45:47+00:00   \n",
              "499    2022-05-13 11:45:34+00:00   \n",
              "808    2022-05-13 12:12:35+00:00   \n",
              "809    2022-05-13 12:12:35+00:00   \n",
              "...                          ...   \n",
              "114952 2022-05-13 15:10:25+00:00   \n",
              "114953 2022-05-13 15:10:25+00:00   \n",
              "114954 2022-05-13 15:10:25+00:00   \n",
              "114955 2022-05-13 15:10:25+00:00   \n",
              "114956 2022-05-13 15:10:25+00:00   \n",
              "\n",
              "                                                     text  \n",
              "497     RT @LapsiaSnehal: It is always nice when the C...  \n",
              "498     mohali: Mohali blast: Babbar Khalsa, gangsters...  \n",
              "499     Polycystic Kidney Disease Symptoms\\n.\\nhttps:/...  \n",
              "808     @AmoneyResists \"Since Rand Paul (R-Moscow) jus...  \n",
              "809     RT @freethought202: Gareth, aged 40, is the fi...  \n",
              "...                                                   ...  \n",
              "114952  RT @redjaspershopp: Just ONE day away! \\nStop ...  \n",
              "114953  RT @GordonBrown: Tragically, we are sleepwalki...  \n",
              "114954  RT @ujjainumc: @ujjainumc jas made Green Net c...  \n",
              "114955  @RockstarGames @GTASeries @_HEALTH_ so you ack...  \n",
              "114956  RT @erdocAA: Nothing I ever learned in medical...  \n",
              "\n",
              "[73349 rows x 5 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-eea1cda7-e96c-4304-be69-594e53704a5e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweetID</th>\n",
              "      <th>AuthorID</th>\n",
              "      <th>lang</th>\n",
              "      <th>created_at</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>1525079862410625024</td>\n",
              "      <td>1299576198591385600</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 11:45:48+00:00</td>\n",
              "      <td>RT @LapsiaSnehal: It is always nice when the C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>1525079857201352704</td>\n",
              "      <td>1334017178</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 11:45:47+00:00</td>\n",
              "      <td>mohali: Mohali blast: Babbar Khalsa, gangsters...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>1525079805674274816</td>\n",
              "      <td>1189832851371347969</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 11:45:34+00:00</td>\n",
              "      <td>Polycystic Kidney Disease Symptoms\\n.\\nhttps:/...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>808</th>\n",
              "      <td>1525086602439057408</td>\n",
              "      <td>1518709954215124993</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 12:12:35+00:00</td>\n",
              "      <td>@AmoneyResists \"Since Rand Paul (R-Moscow) jus...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>809</th>\n",
              "      <td>1525086602195787776</td>\n",
              "      <td>355844222</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 12:12:35+00:00</td>\n",
              "      <td>RT @freethought202: Gareth, aged 40, is the fi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114952</th>\n",
              "      <td>1525131356480581632</td>\n",
              "      <td>1320615780552044544</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 15:10:25+00:00</td>\n",
              "      <td>RT @redjaspershopp: Just ONE day away! \\nStop ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114953</th>\n",
              "      <td>1525131355138494466</td>\n",
              "      <td>20157199</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 15:10:25+00:00</td>\n",
              "      <td>RT @GordonBrown: Tragically, we are sleepwalki...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114954</th>\n",
              "      <td>1525131354853154816</td>\n",
              "      <td>1468522753909489664</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 15:10:25+00:00</td>\n",
              "      <td>RT @ujjainumc: @ujjainumc jas made Green Net c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114955</th>\n",
              "      <td>1525131354815479808</td>\n",
              "      <td>1001715489951842304</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 15:10:25+00:00</td>\n",
              "      <td>@RockstarGames @GTASeries @_HEALTH_ so you ack...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114956</th>\n",
              "      <td>1525131354664488962</td>\n",
              "      <td>597674628</td>\n",
              "      <td>None</td>\n",
              "      <td>2022-05-13 15:10:25+00:00</td>\n",
              "      <td>RT @erdocAA: Nothing I ever learned in medical...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>73349 rows × 5 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eea1cda7-e96c-4304-be69-594e53704a5e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-eea1cda7-e96c-4304-be69-594e53704a5e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-eea1cda7-e96c-4304-be69-594e53704a5e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#create a new df to store filtered tweets\n",
        "db_cleanTweets=pd.DataFrame(columns = ['tweetID', 'tweetsORG','cleanTweets','Hashtags'])"
      ],
      "metadata": {
        "id": "A5TatPIzQGC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data cleaning\n",
        "nlp = spacy.load('en')  \n",
        "nlp.add_pipe(LanguageDetector(), name='language_detector', last=True) \n",
        "\n",
        "for index, row in db_tweets.iterrows():\n",
        "  #detect if english\n",
        "  tweet=row['text']\n",
        "  doc = nlp(tweet) \n",
        "  detect_language = doc._.language \n",
        "  #skip if its not english\n",
        "  if detect_language['language']!='en':\n",
        "      continue\n",
        "  #find all hashtags    \n",
        "  hashtag=re.findall(r'#(\\w+)', tweet)\n",
        "  #remove hashtags, URL, emojis, mention, number, etc \n",
        "  clean=p.clean(tweet)\n",
        "  ith_row=[row['tweetID'], tweet, clean, hashtag]\n",
        "  db_cleanTweets.loc[len(db_cleanTweets)] = ith_row  "
      ],
      "metadata": {
        "id": "luLKpxabWtNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "db_cleanTweets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "8ecSqvjbBnY-",
        "outputId": "c700fbc9-b0ff-4317-ac44-69a3f36e8b45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                   tweetID                                          tweetsORG  \\\n",
              "0      1525079862410625024  RT @LapsiaSnehal: It is always nice when the C...   \n",
              "1      1525079857201352704  mohali: Mohali blast: Babbar Khalsa, gangsters...   \n",
              "2      1525079805674274816  Polycystic Kidney Disease Symptoms\\n.\\nhttps:/...   \n",
              "3      1525086602439057408  @AmoneyResists \"Since Rand Paul (R-Moscow) jus...   \n",
              "4      1525086602195787776  RT @freethought202: Gareth, aged 40, is the fi...   \n",
              "...                    ...                                                ...   \n",
              "63234  1525131356480581632  RT @redjaspershopp: Just ONE day away! \\nStop ...   \n",
              "63235  1525131355138494466  RT @GordonBrown: Tragically, we are sleepwalki...   \n",
              "63236  1525131354853154816  RT @ujjainumc: @ujjainumc jas made Green Net c...   \n",
              "63237  1525131354815479808  @RockstarGames @GTASeries @_HEALTH_ so you ack...   \n",
              "63238  1525131354664488962  RT @erdocAA: Nothing I ever learned in medical...   \n",
              "\n",
              "                                             cleanTweets  \\\n",
              "0      : It is always nice when the CT and OGD correl...   \n",
              "1      mohali: Mohali blast: Babbar Khalsa, gangsters...   \n",
              "2                   Polycystic Kidney Disease Symptoms..   \n",
              "3      \"Since Rand Paul (R-Moscow) just unilaterally ...   \n",
              "4      : Gareth, aged , is the first Australian to re...   \n",
              "...                                                  ...   \n",
              "63234  : Just ONE day away! Stop by to support awaren...   \n",
              "63235  : Tragically, we are sleepwalking into the nex...   \n",
              "63236  : jas made Green Net covering compulsory for u...   \n",
              "63237  so you acknowledged max payne 's year annivers...   \n",
              "63238  : Nothing I ever learned in medical school sai...   \n",
              "\n",
              "                                                Hashtags  \n",
              "0      [FOAMrad, FOAMed, meded, radres, futureradres,...  \n",
              "1      [news, worldnews, auto, entertainment, busines...  \n",
              "2      [symptoms, polycystic, kidney, kidneydisease, ...  \n",
              "3                                                     []  \n",
              "4                                                     []  \n",
              "...                                                  ...  \n",
              "63234                                                 []  \n",
              "63235                                                 []  \n",
              "63236                                                 []  \n",
              "63237                                                 []  \n",
              "63238                                                 []  \n",
              "\n",
              "[63239 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5b84c855-a590-4976-b374-1cb3d79d491d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweetID</th>\n",
              "      <th>tweetsORG</th>\n",
              "      <th>cleanTweets</th>\n",
              "      <th>Hashtags</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1525079862410625024</td>\n",
              "      <td>RT @LapsiaSnehal: It is always nice when the C...</td>\n",
              "      <td>: It is always nice when the CT and OGD correl...</td>\n",
              "      <td>[FOAMrad, FOAMed, meded, radres, futureradres,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1525079857201352704</td>\n",
              "      <td>mohali: Mohali blast: Babbar Khalsa, gangsters...</td>\n",
              "      <td>mohali: Mohali blast: Babbar Khalsa, gangsters...</td>\n",
              "      <td>[news, worldnews, auto, entertainment, busines...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1525079805674274816</td>\n",
              "      <td>Polycystic Kidney Disease Symptoms\\n.\\nhttps:/...</td>\n",
              "      <td>Polycystic Kidney Disease Symptoms..</td>\n",
              "      <td>[symptoms, polycystic, kidney, kidneydisease, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1525086602439057408</td>\n",
              "      <td>@AmoneyResists \"Since Rand Paul (R-Moscow) jus...</td>\n",
              "      <td>\"Since Rand Paul (R-Moscow) just unilaterally ...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1525086602195787776</td>\n",
              "      <td>RT @freethought202: Gareth, aged 40, is the fi...</td>\n",
              "      <td>: Gareth, aged , is the first Australian to re...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63234</th>\n",
              "      <td>1525131356480581632</td>\n",
              "      <td>RT @redjaspershopp: Just ONE day away! \\nStop ...</td>\n",
              "      <td>: Just ONE day away! Stop by to support awaren...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63235</th>\n",
              "      <td>1525131355138494466</td>\n",
              "      <td>RT @GordonBrown: Tragically, we are sleepwalki...</td>\n",
              "      <td>: Tragically, we are sleepwalking into the nex...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63236</th>\n",
              "      <td>1525131354853154816</td>\n",
              "      <td>RT @ujjainumc: @ujjainumc jas made Green Net c...</td>\n",
              "      <td>: jas made Green Net covering compulsory for u...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63237</th>\n",
              "      <td>1525131354815479808</td>\n",
              "      <td>@RockstarGames @GTASeries @_HEALTH_ so you ack...</td>\n",
              "      <td>so you acknowledged max payne 's year annivers...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63238</th>\n",
              "      <td>1525131354664488962</td>\n",
              "      <td>RT @erdocAA: Nothing I ever learned in medical...</td>\n",
              "      <td>: Nothing I ever learned in medical school sai...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>63239 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5b84c855-a590-4976-b374-1cb3d79d491d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5b84c855-a590-4976-b374-1cb3d79d491d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5b84c855-a590-4976-b374-1cb3d79d491d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename='/content/data/cleaned_tweets.csv'\n",
        "db_cleanTweets.to_csv(filename, index = False, encoding='utf-8')"
      ],
      "metadata": {
        "id": "fyTUlSpGPcnW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}